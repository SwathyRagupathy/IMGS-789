{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ad9262-f944-49e8-a772-b81648a57f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from medmnist import INFO, ChestMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "767d0d93-524b-4982-a4a9-22eba6d25a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e46420c-c5a4-4ede-bd45-250c027140bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "threshold = 0.25  # consistent threshold across experiments\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c611e5eb-0877-4ccc-8f39-e07c505a0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from medmnist import INFO, ChestMNIST\n",
    "\n",
    "# Load dataset metadata\n",
    "info = INFO['chestmnist']\n",
    "DataClass = ChestMNIST\n",
    "\n",
    "# Define standard transform (as per MedMNIST recommendation)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "# Load datasets with transforms\n",
    "train_dataset = DataClass(split='train', download=True, transform=transform)\n",
    "test_dataset  = DataClass(split='test',  download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1b91bee-9ef8-4b93-9056-ef5350a85c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 78468\n",
      "Test set size: 22433\n"
     ]
    }
   ],
   "source": [
    "# Check dataset sizes\n",
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\"Test set size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42dd7559-051c-4f39-90eb-d11be7b9df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def create_episode_multilabel(dataset, n_way=5, k_shot=5, q_query=15):\n",
    "    class_to_indices = defaultdict(list)\n",
    "    for idx, (img, labels) in enumerate(dataset):\n",
    "        for cls in range(labels.shape[0]):\n",
    "            if labels[cls] == 1:\n",
    "                class_to_indices[cls].append(idx)\n",
    "\n",
    "    selected_classes = random.sample(list(class_to_indices.keys()), n_way)\n",
    "\n",
    "    support_x, support_y, query_x, query_y = [], [], [], []\n",
    "\n",
    "    for cls in selected_classes:\n",
    "        indices = random.sample(class_to_indices[cls], k_shot + q_query)\n",
    "        for i in range(k_shot):\n",
    "            img, labels = dataset[indices[i]]\n",
    "            support_x.append(img)\n",
    "            support_y.append(torch.tensor(labels[selected_classes]))\n",
    "        for i in range(k_shot, k_shot + q_query):\n",
    "            img, labels = dataset[indices[i]]\n",
    "            query_x.append(img)\n",
    "            query_y.append(torch.tensor(labels[selected_classes]))\n",
    "\n",
    "    return (torch.stack(support_x), torch.stack(support_y),\n",
    "            torch.stack(query_x), torch.stack(query_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d05d836-41cf-4efe-85e9-9e1710efae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtoNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128), nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4dcdf67-bdd9-4a32-810c-4557086a4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_protonet(model, dataset, n_way=5, k_shot=5, q_query=15, num_episodes=300):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        support_x, support_y, query_x, query_y = create_episode_multilabel(dataset, n_way, k_shot, q_query)\n",
    "        support_x, support_y = support_x.to(device), support_y.to(device)\n",
    "        query_x, query_y = query_x.to(device), query_y.to(device)\n",
    "\n",
    "        support_embeddings = model(support_x)\n",
    "        query_embeddings = model(query_x)\n",
    "\n",
    "        prototypes = []\n",
    "        for i in range(n_way):\n",
    "            cls_mask = (support_y[:, i] == 1)\n",
    "            if cls_mask.sum() == 0:\n",
    "                prototypes.append(torch.zeros_like(support_embeddings[0]))\n",
    "            else:\n",
    "                prototypes.append(support_embeddings[cls_mask].mean(dim=0))\n",
    "        prototypes = torch.stack(prototypes)\n",
    "\n",
    "        logits = -torch.cdist(query_embeddings, prototypes)\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, query_y.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if episode % 50 == 0:\n",
    "            print(f\"[{episode}/{num_episodes}] Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0d45be4-8dda-40e1-ad12-4018225dbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_selected_metrics(model, dataset, n_way=5, k_shot=5, q_query=15, test_episodes=300, threshold=0.25):\n",
    "    model.eval()\n",
    "    f1_scores, aurocs, precisions, recalls = [], [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(test_episodes):\n",
    "            support_x, support_y, query_x, query_y = create_episode_multilabel(dataset, n_way, k_shot, q_query)\n",
    "            support_x, support_y = support_x.to(device), support_y.to(device)\n",
    "            query_x, query_y = query_x.to(device), query_y.to(device)\n",
    "\n",
    "            support_embeddings = model(support_x)\n",
    "            query_embeddings = model(query_x)\n",
    "\n",
    "            prototypes = []\n",
    "            for i in range(n_way):\n",
    "                cls_mask = (support_y[:, i] == 1)\n",
    "                if cls_mask.sum() == 0:\n",
    "                    prototypes.append(torch.zeros_like(support_embeddings[0]))\n",
    "                else:\n",
    "                    prototypes.append(support_embeddings[cls_mask].mean(dim=0))\n",
    "            prototypes = torch.stack(prototypes)\n",
    "\n",
    "            \n",
    "            logits = -torch.cdist(query_embeddings, prototypes)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            preds = (probs > threshold).float()\n",
    "\n",
    "            preds_np = preds.cpu().numpy()\n",
    "            targets_np = query_y.cpu().numpy()\n",
    "\n",
    "            if np.sum(targets_np) > 0:\n",
    "                f1 = f1_score(targets_np, preds_np, average='micro', zero_division=0)\n",
    "                precision = precision_score(targets_np, preds_np, average='micro', zero_division=0)\n",
    "                recall = recall_score(targets_np, preds_np, average='micro', zero_division=0)\n",
    "                try:\n",
    "                    auroc = roc_auc_score(targets_np, probs.cpu().numpy(), average='micro')\n",
    "                except:\n",
    "                    auroc = 0\n",
    "                f1_scores.append(f1)\n",
    "                precisions.append(precision)\n",
    "                recalls.append(recall)\n",
    "                aurocs.append(auroc)\n",
    "\n",
    "    return {\n",
    "        'avg_f1_score': np.mean(f1_scores),\n",
    "        'avg_auroc': np.mean(aurocs),\n",
    "        'avg_precision': np.mean(precisions),\n",
    "        'avg_recall': np.mean(recalls)\n",
    "    }\n",
    "\n",
    "def print_selected_metrics(name, metrics):\n",
    "    print(f\"\\n==== {name} Metrics ====\")\n",
    "    print(f\"F1-Score   : {metrics['avg_f1_score']:.4f}\")\n",
    "    print(f\"AUROC      : {metrics['avg_auroc']:.4f}\")\n",
    "    print(f\"Precision  : {metrics['avg_precision']:.4f}\")\n",
    "    print(f\"Recall     : {metrics['avg_recall']:.4f}\")\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb0b07ba-bbe5-4002-abea-6b1b6191e698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/300] Loss: 0.6342\n",
      "[50/300] Loss: 0.5727\n",
      "[100/300] Loss: 0.6049\n",
      "[150/300] Loss: 0.6242\n",
      "[200/300] Loss: 0.5702\n",
      "[250/300] Loss: 0.5445\n"
     ]
    }
   ],
   "source": [
    "# One-Shot (k=1)\n",
    "model_1shot = ProtoNet()\n",
    "train_protonet(model_1shot, train_dataset, n_way=5, k_shot=1, num_episodes=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "884bc879-92fd-46c5-8573-bce176948b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/300] Loss: 0.6509\n",
      "[50/300] Loss: 0.5902\n",
      "[100/300] Loss: 0.5378\n",
      "[150/300] Loss: 0.5417\n",
      "[200/300] Loss: 0.6053\n",
      "[250/300] Loss: 0.5482\n"
     ]
    }
   ],
   "source": [
    "# Few-Shot (k=5)\n",
    "model_5shot = ProtoNet()\n",
    "train_protonet(model_5shot, train_dataset, n_way=5, k_shot=5, num_episodes=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ea35672-71a5-4a96-bfeb-5999e8ab9cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== One-Shot Metrics ====\n",
      "F1-Score   : 0.3780\n",
      "AUROC      : 0.5454\n",
      "Precision  : 0.2877\n",
      "Recall     : 0.5630\n",
      "==============================\n",
      "\n",
      "==== Few-Shot 5-Shot Metrics ====\n",
      "F1-Score   : 0.4172\n",
      "AUROC      : 0.5800\n",
      "Precision  : 0.3001\n",
      "Recall     : 0.6902\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# One-Shot (k=1) Test \n",
    "metrics_1shot = evaluate_selected_metrics(model_1shot, test_dataset, n_way=5, k_shot=1, test_episodes=300)\n",
    "print_selected_metrics(\"One-Shot\", metrics_1shot)\n",
    "\n",
    "# Few-Shot (k=5) \n",
    "metrics_5shot = evaluate_selected_metrics(model_5shot, test_dataset, n_way=5, k_shot=5, test_episodes=300)\n",
    "print_selected_metrics(\"Few-Shot 5-Shot\", metrics_5shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77016e3f-1b33-4e57-a3b2-99367f910202",
   "metadata": {},
   "source": [
    "### Self-Supervised Pretraining using RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edda729f-336a-4c63-94e4-ec986743e169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "# Self-supervised dataset class for RotNet task\n",
    "class RotNetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.rotations = [0, 90, 180, 270]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset) * 4\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        base_idx = idx // 4\n",
    "        rot_label = idx % 4\n",
    "        img, _ = self.base_dataset[base_idx]  # ignore true label\n",
    "        rotated_img = TF.rotate(img, self.rotations[rot_label])\n",
    "        return rotated_img, rot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b84279f-0113-4464-8bd2-64c83f514947",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128), nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Linear(128, 4)  # 4 rotation classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        return self.classifier(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "894ec8b3-e749-4111-a950-3b4669e1a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load RotNet training dataset from ChestMNIST train set\n",
    "rotnet_train = RotNetDataset(train_dataset)\n",
    "rotnet_loader = DataLoader(rotnet_train, batch_size=64, shuffle=True)\n",
    "\n",
    "def train_rotnet(model, dataloader, num_epochs=10):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"[RotNet Epoch {epoch+1}] Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2ebf2af-2db1-4103-8456-220a57eb09de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RotNet Epoch 1] Loss: 70.6259\n",
      "[RotNet Epoch 2] Loss: 33.4759\n",
      "[RotNet Epoch 3] Loss: 27.9486\n",
      "[RotNet Epoch 4] Loss: 24.1288\n",
      "[RotNet Epoch 5] Loss: 21.3974\n",
      "[RotNet Epoch 6] Loss: 19.1500\n",
      "[RotNet Epoch 7] Loss: 16.2586\n",
      "[RotNet Epoch 8] Loss: 14.2985\n",
      "[RotNet Epoch 9] Loss: 12.6736\n",
      "[RotNet Epoch 10] Loss: 10.7863\n"
     ]
    }
   ],
   "source": [
    "# Train RotNet\n",
    "rotnet_model = RotNet()\n",
    "train_rotnet(rotnet_model, rotnet_loader, num_epochs=10)\n",
    "\n",
    "# Save pretrained encoder\n",
    "pretrained_encoder = rotnet_model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc7bce77-4a0b-43db-8417-e8cd2d5f0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtoNetWithRotNet(nn.Module):\n",
    "    def __init__(self, pretrained_encoder):\n",
    "        super().__init__()\n",
    "        self.encoder = pretrained_encoder  \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6a57ec8f-6fac-44e6-b40f-d6b05105e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_protonet(model, dataset, n_way=5, k_shot=5, q_query=15, num_episodes=300):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        support_x, support_y, query_x, query_y = create_episode_multilabel(dataset, n_way, k_shot, q_query)\n",
    "        support_x, support_y = support_x.to(device), support_y.to(device)\n",
    "        query_x, query_y = query_x.to(device), query_y.to(device)\n",
    "\n",
    "        support_embeddings = model(support_x)\n",
    "        query_embeddings = model(query_x)\n",
    "\n",
    "        prototypes = []\n",
    "        for i in range(n_way):\n",
    "            cls_mask = (support_y[:, i] == 1)\n",
    "            if cls_mask.sum() == 0:\n",
    "                prototypes.append(torch.zeros_like(support_embeddings[0]))\n",
    "            else:\n",
    "                prototypes.append(support_embeddings[cls_mask].mean(dim=0))\n",
    "        prototypes = torch.stack(prototypes)\n",
    "\n",
    "        logits = -torch.cdist(query_embeddings, prototypes)\n",
    "        loss = nn.BCEWithLogitsLoss()(logits, query_y.float())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if episode % 50 == 0:\n",
    "            print(f\"[Episode {episode}] Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb0c0a5d-d828-4f01-973c-85bd69393903",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rotnet_proto = ProtoNetWithRotNet(pretrained_encoder=pretrained_encoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "998f7c50-abd9-4625-a2be-b14459dd8699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode 0] Loss: 2.5259\n",
      "[Episode 50] Loss: 0.5617\n",
      "[Episode 100] Loss: 0.6101\n",
      "[Episode 150] Loss: 0.5767\n",
      "[Episode 200] Loss: 0.6191\n",
      "[Episode 250] Loss: 0.6367\n"
     ]
    }
   ],
   "source": [
    "train_protonet(model_rotnet_proto, train_dataset, n_way=5, k_shot=5, q_query=15, num_episodes=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a23eef7a-150f-4ae0-91d8-cba051966155",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_rotnet_proto = evaluate_selected_metrics(model_rotnet_proto, test_dataset, n_way=5, k_shot=5, test_episodes=300, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e85e22e6-c8ce-4d30-8352-55f4b0f16102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Few-Shot + RotNet Metrics ====\n",
      "F1-Score   : 0.4031\n",
      "AUROC      : 0.5419\n",
      "Precision  : 0.2818\n",
      "Recall     : 0.7128\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "print_selected_metrics(\"Few-Shot + RotNet\", metrics_rotnet_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b96427-dea3-4e24-8e28-7fb432521e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33726089-e7bb-40ad-b8ec-5daa8fcc3b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75cd4e-4e31-452c-8c0f-9eb968cf34bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
